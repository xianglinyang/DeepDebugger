{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop your own visualization method\n",
    "This serve as an template of Visualization in pytorch. Visualization methods contain four parts, including initialization, edge dataset construction, training, visualize_embedding and evluation. Next we will go step by step on how to implement your own visualization method in our framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from singleVis.custom_weighted_random_sampler import CustomWeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define different components at corresponding class. You can import current implementations or define your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "# >>>>>>>>>> Define different visualization components in the following file and import them\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.losses import Loss # and other Losses \n",
    "from singleVis.edge_dataset import DataHandlerAbstractClass\n",
    "from singleVis.trainer import TrainerAbstractClass\n",
    "from singleVis.data import DataProviderAbstractClass\n",
    "from singleVis.spatial_edge_constructor import SpatialEdgeConstructorAbstractClass\n",
    "from singleVis.projector import ProjectorAbstractClass\n",
    "from singleVis.eval.evaluator import EvaluatorAbstractClass\n",
    "# <<<<<<<<<< Define different visualization components in the following file and import them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>\n",
    "VIS_METHOD = \"your visualization name\"\n",
    "CONTENT_PATH = \"path/to/your/subject_models\"\n",
    "# <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "\n",
    "# Define your dataset hyperparameters in config\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]\n",
    "\n",
    "# load parameters from config.json\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define data_provider\n",
    "data_provider = DataProviderAbstractClass(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)\n",
    "# <<<<<<<<<< Define data_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own visualization models\n",
    "model = VisModel(encoder_dims=[100,20,2], decoder_dims=[2,50,100])  # placeholder\n",
    "# <<<<<<<<<< Define your own visualization models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own Projector\n",
    "projector = ProjectorAbstractClass()\n",
    "# <<<<<<<<<< Define your own Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Edge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own Losses\n",
    "criterion = Loss()\n",
    "# <<<<<<<<<< Define your own Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own training parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=.1)\n",
    "# <<<<<<<<<< Define your own training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own Edge dataset\n",
    "t0 = time.time()\n",
    "spatial_cons = SpatialEdgeConstructorAbstractClass(data_provider)\n",
    "edge_to, edge_from, probs, feature_vectors = spatial_cons.construct()\n",
    "t1 = time.time()\n",
    "spatial_cons.record_time(data_provider.model_path, \"time_{}.json\".format(VIS_MODEL_NAME), \"complex_construction\", t1-t0)\n",
    "# <<<<<<<<<< Define your own Edge dataset\n",
    "\n",
    "# remove edges with low weight (optional) \n",
    "probs = probs / (probs.max()+1e-3)\n",
    "eliminate_zeros = probs>1e-3\n",
    "edge_to = edge_to[eliminate_zeros]\n",
    "edge_from = edge_from[eliminate_zeros]\n",
    "probs = probs[eliminate_zeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own dataset\n",
    "dataset = DataHandlerAbstractClass(edge_to, edge_from, feature_vectors)\n",
    "# <<<<<<<<<< Define your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an edge dataset\n",
    "n_samples = int(np.sum(S_N_EPOCHS * probs) // 1)\n",
    "# chose sampler based on the number of dataset\n",
    "if len(edge_to) > 2^24:\n",
    "    sampler = CustomWeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "else:\n",
    "    sampler = WeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "edge_loader = DataLoader(dataset, batch_size=1000, sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your own trainer\n",
    "trainer = TrainerAbstractClass(model, criterion, optimizer, lr_scheduler, edge_loader, DEVICE)\n",
    "# <<<<<<<<<< Define your own trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=time.time()\n",
    "trainer.train(PATIENT, MAX_EPOCH)\n",
    "t3 = time.time()\n",
    "\n",
    "trainer.record_time(data_provider.model_path, \"time_{}.json\".format(VIS_MODEL_NAME), \"training\", t3-t2)\n",
    "save_dir = \"path/to/model\"\n",
    "trainer.save(save_dir=save_dir, file_name=\"{}\".format(VIS_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. visualize embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your Visualizer\n",
    "from singleVis.visualizer import VisualizerAbstractClass\n",
    "vis = VisualizerAbstractClass(data_provider, projector)\n",
    "# <<<<<<<<<< Define your Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"path/to/generated/imgs\"\n",
    "os.makedirs(save_dir)\n",
    "for epoch in range(EPOCH_START, EPOCH_END+1, EPOCH_PERIOD):\n",
    "    vis.savefig(epoch, path=os.path.join(save_dir, \"{}_{}_{}.png\".format(DATASET, epoch, VIS_METHOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define your evaluator\n",
    "evaluator = EvaluatorAbstractClass(data_provider, projector)\n",
    "# <<<<<<<<<< Define your evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_epochs = range(EPOCH_START, EPOCH_END, EPOCH_PERIOD)\n",
    "for eval_epoch in eval_epochs:\n",
    "    evaluator.save_epoch_eval(eval_epoch, 15, temporal_k=5, file_name=\"{}_{}\".format(VIS_METHOD, EVALUATION_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap your own visualization\n",
    "Wrap your customized visualization at \"~/DLVisDebugger/Strategy.py\" with the following format.\n",
    "```python\n",
    "class StrategyAbstractClass(ABC):\n",
    "    def __init__(self, CONTENT_PATH, config):\n",
    "        self.config = config\n",
    "        self.CONTENT_PATH = CONTENT_PATH\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _init(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _preprocess(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _evaluate(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _visualize(self):\n",
    "        pass\n",
    "\n",
    "    def visualize_embedding(self):\n",
    "        self._init()\n",
    "        self._preprocess()\n",
    "        self._train()\n",
    "        self._evaluate()\n",
    "        self._visualize()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call your method \n",
    "import json\n",
    "CONTENT_PATH = \"/path/to/dataset\"\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "customize_config = config[VIS_METHOD]\n",
    "cs = CustomizeStrategy(CONTENT_PATH, customize_config)\n",
    "cs.visualize_embedding()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('timevis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c8ca38b42f6175a6e2def9ce469b2c78a69830a666e0f6ae7493f7267c2706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
