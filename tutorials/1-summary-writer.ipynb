{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training instrumentation\n",
    "This tutorial explains how to instrument training and save checkpoints to a certain format. We use cifar10 trained with resnet18 as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Define summary writer\n",
    "sys.path.append(\"..\")\n",
    "from writer.summary_writer import SummaryWriter\n",
    "log_dir = \"path/to/content\" # User define\n",
    "writer = SummaryWriter(log_dir)\n",
    "# <<<<<<<<<< Define summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# record train data using test transform to avoid randomness\n",
    "record_trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_test)\n",
    "record_trainloader = torch.utils.data.DataLoader(\n",
    "    record_trainset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>Record Data\n",
    "writer.add_training_data(record_trainloader) # use test_transform\n",
    "writer.add_testing_data(testloader)\n",
    "# <<<<<<<<<<Record Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "The model need to have certain requirements.\n",
    "\n",
    "1. embedded with feature and prediction function\n",
    "```python\n",
    "net = ResNet18()\n",
    "net.feature() # (N,...)->(N,M), output a 2 dimensional feature, N samples with feature length of M\n",
    "net.prediction() # (N, M)->(N, C), C-class classification problem, output logits (the layer before softmax or log-softmax)\n",
    "```\n",
    "2. put it in \"model.py\" under folder \"CONTENT_PATH/Model\"\n",
    "3. the name of model should be in config\n",
    ">for example, in our case, config[\"NET\"] == \"ResNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> Building model..\n",
    "net = ResNet18()    # choose your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training\n",
    "def train():\n",
    "    net.train()\n",
    "    for _, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## record checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_id = 0\n",
    "idxs = list(range(len(trainset)))\n",
    "for epoch in range(1,200,1):\n",
    "    train()\n",
    "    if epoch % 10 == 0:\n",
    "        # >>>>>>>>>>record checkpoint for every 10 epochs\n",
    "        writer.add_checkpoint_data(net.state_dict(), idxs, epoch, prev_id)\n",
    "        # <<<<<<<<<<record checkpoint for every 10 epochs\n",
    "    prev_id = epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Record Config\n",
    "config_dict = {\n",
    "    \"SETTING\": \"normal\",\n",
    "    \"CLASSES\": classes, \n",
    "    \"GPU\":\"1\",\n",
    "    \"DATASET\": \"cifar10\",\n",
    "    \"EPOCH_START\": 1,\n",
    "    \"EPOCH_END\": 200,\n",
    "    \"EPOCH_PERIOD\": 1,\n",
    "    \"TRAINING\": {\n",
    "        \"NET\": \"ResNet18\", # name it after your net\n",
    "        \"num_class\": 10,\n",
    "        \"train_num\": 60000,\n",
    "        \"test_num\": 10000,\n",
    "    },\n",
    "    \"VISUALIZATION\":{\n",
    "        \"PREPROCESS\":1,\n",
    "        \"BOUNDARY\":{\n",
    "            \"B_N_EPOCHS\": 0,\n",
    "            \"L_BOUND\":0.5,\n",
    "        },\n",
    "        \"INIT_NUM\": 300,\n",
    "        \"ALPHA\":1,\n",
    "        \"BETA\":1,\n",
    "        \"MAX_HAUSDORFF\":0.33,\n",
    "        \"LAMBDA\": 1,\n",
    "        \"S_LAMBDA\": 1,\n",
    "        \"ENCODER_DIMS\":[512,256,256,256,2],\n",
    "        \"DECODER_DIMS\":[2,256,256,256,512],\n",
    "        \"N_NEIGHBORS\":15,\n",
    "        \"MAX_EPOCH\": 20,\n",
    "        \"S_N_EPOCHS\": 5,\n",
    "        \"T_N_EPOCHS\": 20,\n",
    "        \"PATIENT\": 3,\n",
    "        \"RESOLUTION\":300,\n",
    "        \"VIS_MODEL_NAME\": \"DeepDebugger\",\n",
    "        \"EVALUATION_NAME\": \"test_evaluation_DeepDebugger\"\n",
    "    }\n",
    "}\n",
    "# <<<<<<<<<< Record Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save config\n",
    "config = dict()\n",
    "config[\"DeepDebugger\"] = config_dict\n",
    "with open(os.path.join(log_dir, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>> Choose a visualization method to visualize embedding\n",
    "from Strategy import DeepDebugger\n",
    "dd = DeepDebugger(config_dict)\n",
    "dd.visualize_embedding()\n",
    "# <<<<<<<<<< Choose a visualization method to visualize embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "Starting server and frontend to interact with our tool. See tutorial/2-start-services."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('timevis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c8ca38b42f6175a6e2def9ce469b2c78a69830a666e0f6ae7493f7267c2706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
